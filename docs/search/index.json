[{"content":" Berättelserna är att:\n Svenska banker är slimmade och välskötta företag. Deras centrala plats i ekonomin reflekteras i hälsosamma vinster, hög kundnöjdhet och god kapitaltäckningsgrad. De fyller en viktig roll i ekonomins kapitalförsörjning, en förutsättning för entreprenörskap och företagande. Svenska banker är krympande och förlegade institutioner som tillhör den gamla ekonomin. De ersätts allt mer av fintech-bolag, oberoende kapitalförvaltare, artificiell intelligens för effektivare låneprövning och e-kronor eller fristående tjänster för transaktionskonton. Svenska banker har byggt sina höga vinster på riskfylld utlåning till bostadsköpare. De lärdomar de inte drog av finanskrisen 2008 kunde ha stoppat framväxten av den bostadsbubbla som kommer att utlösa nästa finanskris.  Hur sker förändring? Ett sätt att tänka på förändring är att se kriser som ett impetus för strukturella omvandlingar. Gamla strukturer tenderar att överleva bortom sitt bäst före-datum tack vare historisk spårbundenhet, det Douglass North kallade för path dependance, och befintligt momentum. Exempelvis så fanns teknologin på plats för att möjliggöra hemarbete för många arbetare redan innan Covid 19-pandemin. Pandemin blev den utlösande faktorn som blottade spårbundenheten i en arbetskultur som egentligen var förlegad. För ekonomin så innebär förändringen ett strukturellt skifte bort från transport och kontor till tech-företag som möjliggör distansarbete och bostäder. Mycket tyder på att de svenska storbankernas affärsmodell bygger på en liknande historisk spårbundenhet. Varför blev inte finanskrisen den utlösande faktorn som inledde en meningsfull strukturomvandling av den svenska banksektorn? Svenska storbanker är väldigt lönsamma. Men är det ett tecken på att de gör ett bra jobb, som i den första berättelsen, eller på en slags kollegialt oligopoliserad marknad för bostadslån, som i den tredje?\nBerättelse 3 Den sista berättelse fick senast gehör av Andreas Cervenka och Carl Schlyter i podden Systemskiftet. De beskriver hur bankerna utnyttjar sin grindvaktsfunktion på bostadsmarknaden för att driva bostadspriserna högre varpå lånen blir större och fickorna med ränteslantar allt tyngre. Cervenka påstår att svenska banker har en kapitaltäckning för sina utestående lån på ca 5%. Det innebär en hävstång på 20 gånger. Otänkbart för de flesta företag och i strid med de internationella regleringarna i både Basel II och i det nya stramare Basel III. Stämmer det? Svart på vitt så stämmer det. Men den faktiska berättelsen är mer invecklad.\nPeter Thiel har ett karaktäristiskt sätt att dela upp tillväxt på i två olika kategorier - globalisering och teknologi. Globalisering är en typ av horisontell tillväxt där existerande teknologier tillämpas på nya marknader medan teknologisk tillväxt är vertikal. Efter Soviets fall så stod de då nyligen liberaliserade baltiska ekonomierna utan ett eget hemväxt bankväsende, och därmed vidöppna för de opportunistiska svenska, och fläckvis danska, banker. I en horisontell rörelse som speglades på bred front på många andra håll i världen vid tiden - i Asien, Sydamerika och Indien - så flyttade de svenska storbankerna in. Det var inte bara handel som liberaliserades. Kapital kunde för första gången sedan 1914 strömma relativt fritt över nationsgränser. Växande ekonomier som de i Baltikum förväntas visserligen importera kapital. Men inte för att finansiera bostadsköp och konsumtion. Utan för att investera i fabriker som på sikt kan bidra till export och ett balanserat kapitalkonto. Balterna hade dessutom inga meningsfulla mängder pengar att stoppa in på sina nya svenska löne- och sparkonton. Utlåningen finansierades istället med kortfristiga lån på den internationella kapitalmarknaden med den svenska verksamheten som säkerhet. Att svenska banker finansierar sin utlåning på de globala kapitalmarknaderna var något som allmänheten, och sannolikt även många tjänstemän på berörda myndigheter, först blev varse om när SEBs och Swedbanks verksamheter i Baltikum imploderade lika snabbt som likviditeten på kapitalmarknaderna ströps under finanskrisens höst 2008.\nLow risk high reward När vi tittar på svenska bankers verksamhet i Sverige idag så kan vi se en rörelse i den baltiska riktningen även här. Inlåningen är internationell och betoningen har skiftat bort från utlåning till företag och mot bostadsköpande hushåll.\n \nDet ger oss anledning att ifrågasätta berättelse 1 om de svenska bankernas roll som näringslivets kapitalförsörjare. Faktum är att om vi tittar på vilka som har investerat i några av svenskt näringslivs större och mer kapitalkrävande tillväxtbolag de senaste 10 åren, som Volvo AB, Volvo lastvagnar, Klarna, Spotify och Northvolt, så är svenska banker, oaktat några pensionsfonder, nästan helt frånvarande. I deras ställe finner vi kinesiska och tyska konkurrenter, amerikanska investeringsbanker och oberoende kapitalförvaltare. Svenskt kapital är istället till viss del uppbundet i den svenska bostadsmarknaden, som har varit en väldigt lönsam affär för de svenska bankerna.\nEtt sätt att mäta lönsamheten på är att titta på bankernas räntenetto. Det är skillnaden mellan vad bankerna betalar för att låna pengar, alltså för att finansiera utlåningen, och vad bankerna tar betalt i form av ränta på bostadslån. Ungefär 70% av finansieringen för att bostadslön sker genom att bankerna emitterar obligationer på den internationella kapitalmarknaden, företrädesvis i EUR och USD. Finansinspektionen uppskattar räntenettot till att ha varit 1,44% under första kvartalet 2021. Med en bolåneränta på kort löptid som ligger på ungefär detsamma så kan vi se att bankerna själva lånar i princip gratis. Att riskpremien för bankernas finansiering är så låg beror delvis på explicita och implicita garantier ifrån svenska myndigheter i händelse av kris. Sammantaget så är det en tacksam kalkyl att översatta till generösa vinster. Svenska bankers rörelseresultat som andel av alla svenska icke-finansiella företags rörelseresultat har legat på ca 24% sedan finanskrisen och sedan fallit ner till ca 20%.\n \nBerättelse 3, Cervenkas och Schlyters berättelse, är den om ett korrupt oligopol. Berättelse 2 är den om ett bankväsende som tillhör den gamla ekonomin som kommer att ersättas av tillväxt i nya teknologier. Om vi kombinerar de två berättelserna så kan vi ställa frågan: är det hållbart att en sektion av svenskt näringsliv genererar nästan 1/5 av övriga näringslivets vinster genom att fungera som bostadsmarknaden grindvakter? Kan belöningen rimligtvis vara så stor för att slussa in globalt kapital på den svenska bostadsmarknaden i en process som mer eller mindre kan skötas med algoritmer?\nEn siffra är väll en siffra? För att komma vidare här så behöver vi förstå hur Cervenkas syn på bankernas kapitaltäckning skiljer sig från bankernas egen. Basel III fokuserar likt sin föregångare Basel II på riskvägda tillgångar. När Cervenka säger att bankerna har en kapitaltäckningsgrad på 5% så avser det tillgångarnas egentliga värde. Den globala standarden är dock att tillskriva vissa typer av tillgångar, som exempelvis ett lån med en bostad som underliggande säkerhet, en lägre riskvikt. Det innebär i teorin att en låneportfölj på SEK 100 miljarder smått magiskt kan återuppstå som en låneportfölj på SEK 50 miljarder. I samma slag sjunker kapitalkravet med hälften. I verkligheten kan skillnaden vara ännu mer dramatisk.\n \nPå ett sätt är det rimligt att lån med en underliggande säkerhet som en bostad inte ska behöva motsvaras av samma mängd kapital som ett lån utan en underliggande säkerhet. Problemet är att de svenska storbankerna har tillåtits tillämpa egna modeller för att räkna fram vilken riskvikt ett lån ska ha. Det är sannolikt därför ökningen i kapital som andel av just riskvägda tillgångar har kunnat vara så stor och volatil. Det är till viss del en pappersexercis som ligger bakom ökningen. Svenska storbanker har en historia av liknande metoder. När den Estniska centralbanken anade oråd 2006 så höjde man kapitaltäckningskravet från 8 till 10% och tillämpade dessutom en riskvikt på 100% för bostadslån. Svenska banker besvarade det nya kravet genom att flytta en typ av kapital av låg kvalité från sina svenska verksamheter till sina estniska dotterbolag. I Basel III kan inte denna typ av lågkvalitativa kapital användas på samma sätt.\nEtt inslag i Basel III är att bankerna tvingas ha en så kallad likviditetsbuffert som ska fungera som en flytande krockkudde i händelse av att kapitalmarknaderna fryser till is som de gjorde hösten 2008. I praktiken innebär det att bankerna kommer tvingas att själva explicit bära mer av de kostnader som staten och skattebetalarna hittills har burit genom implicita och explicita löften till bankerna samt dess finansiärer och kunder i händelse av kris. Enkelt uttryckt så kommer bankerna att tvingas att betala mer av sin egen försäkringspremie. Om vi till det lägger amorteringskravet och finansinspektionens tendens att tillämpa ännu strängare regler, utanför Basel, så ser vi att det byråkratiska och politiska tålamodet med bankernas nuvarande affärsmodell har börjat tryta.\nI takt med att reglerna i Basel III implementeras så kommer storbankernas avtryck i ekonomin sannolikt att minska. Bankernas branschorganisation protesterar inte så ljudligt som de gör mot regleringarna utan anledning. Vi ser även att storbankernas vinster har börjat sjunka de senaste 3 till 4 åren och att tech och fintech-bolag står redo att plocka marknadsandelar från storbankerna på deras mest lönsamma områden.\nSammantaget bådar det illa för de svenska storbankerna. Den horisontella tillväxten i Baltikum hade kunnat bli ett par av storbankernas undergång om inte staten hade klivit in. Och den vertikala tillväxten har till viss del uteblivit. Teknologi, att göra något nytt, är ett direkt hot mot storbankernas oligopolliknande ställning på bolånemarknaden. När något nytt kommer så lär det ske utanför storbankernas paraply. En marknad med så höga marginaler skapar starka incitament för outsiders. Det hänger till viss del på politiken och byråkratin att inte reglera bort konkurrensen. Sannolikheten för det minskar i takt med att det politiska och byråkratiska välviljan till storbankerna tryter.\nAnledningen till att finanskrisen inte blev samma impetus till förändring för banksektorn som Covid 19-pandemin blev för hur vi arbetar - kan ha varit att teknologin och byråkratin inte var redo. Berättelse 2, där den nya ekonomin ersätter den gamla, kan förverkligas först nu. Eftersom att bankernas nuvarande affärsmodell är att sila en inte oansenlig del av den svenska ekonomin genom sitt finmaskiga barder i sin relativt osofistikerade funktion som bostadsmarknaden grindvakter, så är incitamenten starka att utmana status quo. Tillsammans med den trytande politiska välviljan mot storbankerna så finns det mycket som tyder på att de kommer att förlora sin särställning i svensk ekonomi.\nKällor: Basel Committee on Banking Supervision. (2013. Analysis of risk-weighted assets for credit risk in the banking book. https://www.bis.org/publ6.pdf\nEesti Pank (2007). Financial Stability Review 1/2007. https://www.eestipank.ee/en/publication/financial-stability-review/2007/financial-stability-review-12007\nFinansinspektionen (2017). Baselöverenskommelse om bankers kapitaltäckning klar*.*\nhttps://www.fi.se/sv/publicerat/pressmeddelanden/2017/baseloverenskommelse-om-bankers-kapitaltackning-klar/\nRiksbanken (2020). Storbankernas finansiering och dess påverkan på hushållens bolåneräntor. Ekonomiska kommentarer)\nhttps://www.riksbank.se/globalassets/media/rapporter/ekonomiska-kommentarer/svenska/2020/storbankernas-finansiering-och-dess-paverkan-pa-hushallens-bolanerantor.pdf\nRiksbanken (2016). Penningpolitisk rapport 2016 http://archive.riksbank.se/Documents/Rapporter/PPR/2016/160421/rap_ppr_ruta1_160421_sve.pdf\nSCBs finansmarknadsstatistik (2021)\nSOU 2013:6. Att förebygga och hantera finansiella kriser: delbetänkande av Finanskriskommittén\nSwedish Banker’s Association (2016). Cumulative impact of financial regulation in Sweden. Available at: https://www.swedishbankers.se/media/2835/cumulative-impact-of-financial-regulation.pdf.\n","date":"2021-01-31T00:00:00Z","image":"https://dfornis.github.io/dfornis/p/beh%C3%B6vs-de-svenska-storbankerna/nicolas-perondi--Ho_obgLFs4-unsplash_hudba9150e16cdf60946dabab36cfea944_1220069_120x120_fill_q75_box_smart1.jpg","permalink":"https://dfornis.github.io/dfornis/p/beh%C3%B6vs-de-svenska-storbankerna/","title":"Behövs de svenska storbankerna?"},{"content":" Macroeconomic indicators are traditionally collected with a large lag. This limits their utility in times of high uncertainty. In a pandemic for example, infection rates may accelerate non-linearly (as seen in SIR-models) and are likely to react to variables such as temperature and degree of immunity, many of which remain unknown at the beginning of a pandemic. Nowcasting has been suggested by the Swedish Riksbank (Andersson, Reijer 2015) among others as a tool to make predictions with higher frequency data. Andersson and Reijer use monthly data from surveys, financial markets and similar sources in their nowcasting models to predict Swedish GDP. In this experiment I turned to Google Trends search data to predict movement patterns 1-week-ahead. This time horizon has proven to be relevant in the fast changing landscape of a global pandemic.\nIn practical terms, what would the utility be of predicting changes in movement patterns? A sharp drop in movement in public spaces can be categorized as a black swan event for affected parties, whether they are retail stores, public transport companies or government agencies. Predicting a sudden change in movement patterns might provide these parties with an opportunity to prepare for this change. Predicted movement patterns can also be used as a leading economic indicator.\nTheory The underlying theory has been advocated for as Narrative Economics by Robert Shiller (2017). But it has featured as a theme in many works without being mentioned by name. Its origins can be traced to the 1930\u0026rsquo;s when Keynes coined the phrase animal spirits to capture a characteristic of human behavior beyond what was imagined in the classical models of economics.\nThe assumption is that economic outcomes, to some extent, are a function of the stories and ideas people tell themselves and others. When these stories reach a wide and receptive audience they turn economic behavior into heard behavior. If the narratives that occupy conversations and the minds of people can be measured, they can theoretically be used to predict behavior.\nData To capture the narrative component I used an R library called gtrendsR which runs the API call to Google Trends so that there\u0026rsquo;s no need to cURL it manually. The data is slightly unreliable in the sense that Google provides the amount of hits as an index which is calculated in an unknown black box of magic. The index does however seem to measure changes in search trends over a shorter time horizon reasonably well.\nThe query used in Google Trends was covid and virus. As the interest in Covid-19 rises, people are expected to go online to search for information about the virus or the situation as it unfolds which registers in the index. This variable is countercyclical and should be negatively correlated with movement patterns.\nA procyclical variable was used as well. For this variable my query was snälltåget and sj which are the main operators of long distance trains in Sweden. The assumption here is that people on average go online and search for train tickets 1 week ahead of departure. This variable should be positively correlated with movement patterns.\nFor data on movement patterns I used Google Mobility Report. It was launched in the infancy of the Covid-19 pandemic to track changes in movement patterns. It calculates changes from the same days baseline categorized by country, sub region and type of location/activity (retail and recreation, parks, homes etc).\nModel One of the problems with applying a simple linear regression model is that time series data are likely to be autocorrelated which will express itself as covariance between residuals. One way of resolving this is to model the residuals as an ARIMA-process. I ended up with a (1,1,0) process here. So the model used will be a linear regression with ARIMA errors. Sometimes referred to as ARIMAX, where the X denotes an external regressor.\nThe equation:\n$Y_t = B_1X_{1t} + B_2X_{2t} + n_t$ where $n_t = \\phi n_{t-1} + \\epsilon _t$ is the ARIMA error term. Notations for differencing are missing.\nIn the model, narratives are spread at time t and have an effect on economic behavior at time t+1. Having input variables lagged at t+1 allows the use of an external regressor as fresh input for 1-step-ahead predictions in an ARIMAX model.\nR code Libraries:\nlibrary(tidyverse) library(gtrendsR) # for Google Trends API calls. library(fable) # tidyverse compatible replacement of the forecast package. library(feasts) library(tsibble) library(lubridate) # to help with some weekly time series strangeness. These were the inputs in the Google Trends API call.\nquery \u0026lt;- c(\u0026quot;covid\u0026quot;, \u0026quot;virus\u0026quot;) query2 \u0026lt;- c(\u0026quot;snälltåget\u0026quot;, \u0026quot;sj\u0026quot;) date \u0026lt;- c(\u0026quot;2020-03-01 2021-01-15\u0026quot;) I wrote a function which loops along the query vectors and outputs the mean of hits (index of times searched) in a data frame. This allows for easy experimentation with different search queries and explorative data analysis.\nsearch_se \u0026lt;- data.frame() search_se_mean \u0026lt;- function(query) { for(i in seq_along(search)) { print(search[i]) search_se \u0026lt;- rbind(covid_se, gtrends(keyword = search[i], geo = \u0026quot;SE\u0026quot;, time = date)[[1]]) } search_se_mean \u0026lt;- search_se %\u0026gt;% mutate(week = yearweek(date, week_start = 1)) %\u0026gt;% group_by(week) %\u0026gt;% summarise(hits = mean(hits)) } gtrends_nar \u0026lt;- search_se_mean(query) gtrends_beh \u0026lt;- search_se_mean(query2) gtrends_se \u0026lt;- gtrends_nar %\u0026gt;% full_join(gtrends_beh, by = \u0026quot;week\u0026quot;, suffix = c(\u0026quot;_nar\u0026quot;, \u0026quot;_beh\u0026quot;)) Plotted together:\n \nHits for train travel dropped sharply, as one would expect, and then rebounded over the summer. Hits for the virus jumped up initially but dropped surprisingly fast. Lower levels over the summer was in line with a lower spread of the virus. The index jumped up again in the autumn of 2020, in line with a rising spread of the virus. This inverse relationship between the train travel and virus narrative predictors made intuitive sense and looked promising.\nThe next step was to find out if the predictors had any explanatory power on the leading indicator: movement patterns.\nThe movement data is available at https://www.google.com/covid19/mobility/ I used the .csv-file for global data and did the filtering for my region of interest in R. Once it\u0026rsquo;s loaded, the following code will filter for the target country with country_region_code. I filtered for sub_region_1 = \u0026quot;\u0026quot;  in order to capture data for all of Sweden. The data is then transformed into weeks. Note that data for retail_and_recreation_percent_change_from_baseline was used. The movement patterns being predicted are in retail and recreation areas.\ngmr_se \u0026lt;- gmr %\u0026gt;% mutate(date = as_date(date)) %\u0026gt;% filter(country_region_code == \u0026quot;SE\u0026quot;, sub_region_1 == \u0026quot;\u0026quot;, date \u0026gt;= \u0026quot;2020-03-01\u0026quot; \u0026amp; date \u0026lt;= \u0026quot;2021-01-17\u0026quot;) %\u0026gt;% select(date, retail_and_recreation_percent_change_from_baseline) %\u0026gt;% mutate(week = yearweek(date, week_start = 1)) %\u0026gt;% group_by(week) %\u0026gt;% summarise(across(everything(), list(mean))) %\u0026gt;% rename( \u0026quot;retail\u0026quot; = retail_and_recreation_percent_change_from_baseline_1) %\u0026gt;% select(week, retail) df_se \u0026lt;- gtrends_se %\u0026gt;% # join data sets together left_join(gmr_se) df_se$retail \u0026lt;- df_se$retail + 100 # for potential differencing and log transformations Regressions and scatter plots:  \nInspecting the plots revealed that there was a linear relationship between the variables. The virus search variable did well with 1 lag, while the train ticket search did better without a lag. This will likely depend a lot on the search queries used and on the reliability of Google\u0026rsquo;s black box data. For the purpose of this experiment I stuck with the theory in order to be able to predict 1-step-ahead and continued with lagged variables.\nNext, preparing the data for model fitting.\nval_weeks \u0026lt;- 15 #15 weeks for validating the models df_se_index \u0026lt;- df_se %\u0026gt;% mutate(index = seq_along(1:nrow(.)), type = if_else(index \u0026gt; max(index) - val_weeks, \u0026quot;validation\u0026quot;, \u0026quot;training\u0026quot;), hits_nar_lag = lag(hits_nar), hits_beh_lag = lag(hits_beh)) tsibble_se \u0026lt;- as_tsibble(df_se_index, index = index) # as time series tibble tsibble_se_train \u0026lt;- tsibble_se %\u0026gt;% filter(type == \u0026quot;training\u0026quot;) tsibble_se_val \u0026lt;- tsibble_se %\u0026gt;% filter(type == \u0026quot;validation\u0026quot;) Computing both the TSLM and the ARIMAX (1,1,0) model to see if it makes sense to model the residuals as an ARIMA-process.\nfit_tslm \u0026lt;- tsibble_se_train %\u0026gt;% # fit the model on the training data model(TSLM(retail ~ hits_nar_lag + hits_beh_lag)) fc_tslm \u0026lt;- fit_tslm %\u0026gt;% # forecast with the validation data forecast(new_data = tsibble_se_val) fit_arimax \u0026lt;- tsibble_se_train %\u0026gt;% model(ARIMA(retail ~ hits_nar_lag + hits_beh_lag + pdq(1, 1, 0))) fc_arimax \u0026lt;- fit_arimax %\u0026gt;% forecast(new_data = tsibble_se_val) rmse_tslm \u0026lt;- round(accuracy(fit_tslm)[, 4], digits = 2) # extract RMSE rmse_arimax \u0026lt;- round(accuracy(fit_arimax)[, 4], digits = 2) # extract RMSE fit_tslm %\u0026gt;% gg_tsresiduals() The patterns at index \u0026gt; 18 or so didn\u0026rsquo;t look like a white noise-process. This shows up in the ACF plot as well, even though the spikes aren\u0026rsquo;t significant. The takeaway is that modeling the residuals as an ARIMA-process might prove useful.  TSLM residuals \nFitting the ARIMAX-model below. Evaluating the residuals, they looked more like a stationary white noise process. No significant spikes.\n ARIMAX residuals \nPlotting the models and forecasts produced with Fable:\ntslm_plot \u0026lt;- tsibble_se %\u0026gt;% mutate(color = if_else(type == \u0026quot;training\u0026quot;, \u0026quot;#7e828c\u0026quot;, \u0026quot;#7e828c\u0026quot;)) %\u0026gt;% ggplot(aes(x = index, y = retail)) + geom_line() + autolayer(fc_tslm, alpha = 0.5, color = \u0026quot;#aa332c\u0026quot;) + geom_line(aes(color = color), alpha = 0.8) + geom_line(aes(y = .fitted, color = \u0026quot;#aa332c\u0026quot;), data = augment(fit_tslm)) + labs( title = \u0026quot;TSLM model\u0026quot;, subtitle = paste0(\u0026quot;RMSE = \u0026quot;, rmse_tslm)) + scale_color_identity() arimax_plot \u0026lt;- tsibble_se %\u0026gt;% mutate(color = if_else(type == \u0026quot;training\u0026quot;, \u0026quot;#7e828c\u0026quot;, \u0026quot;#7e828c\u0026quot;)) %\u0026gt;% ggplot(aes(x = index, y = retail)) + geom_line() + autolayer(fc_arimax, alpha = 0.5, color = \u0026quot;#aa332c\u0026quot;) + geom_line(aes(color = color), alpha = 0.8) + geom_line(aes(y = .fitted, color = \u0026quot;#aa332c\u0026quot;), data = augment(fit_arimax)) + labs( title = \u0026quot;ARIMAX model\u0026quot;, subtitle = paste0(\u0026quot;RMSE = \u0026quot;, rmse_arimax)) + scale_color_identity() grid.arrange(tslm_plot, arimax_plot, nrow = 2)  \nI\u0026rsquo;m a bit surprised that the fitted TSLM model performed in parity with the ARIMAX model. I think this might vary a lot depending on the data you end up with. Both models do a decent job on the training data. But they both do a poor job at forecasting the sharp drop in movement that occurs at the end of the time series. I should point out that the ARIMAX model is forecasting the AR(1)-process recursively here. Consequently, there is a mean reversion and it looses its effect over time.\nSince I\u0026rsquo;m interested in the 1-step-ahead forecast, I wrote the loop below to capture what that looks like on the validation data. The point here is to capture the direct 1-step-ahead forecast instead of a recursive forecast, and thereby utilize the full potential of the ARIMAX-model.\ntsibble_se_loop \u0026lt;- data.frame() direct_pred \u0026lt;- data.frame() index \u0026lt;- 15:nrow(tsibble_se) val_weeks = 1 for(i in index) { tsibble_se_loop \u0026lt;- df_se %\u0026gt;% mutate(index = seq_along(1:nrow(.)), hits_nar_lag = lag(hits_nar), hits_beh_lag = lag(hits_beh)) %\u0026gt;% as_tsibble(., index = index) %\u0026gt;% filter(index \u0026lt; index[i]) %\u0026gt;% mutate(type = if_else(index \u0026gt; max(index) - val_weeks, \u0026quot;validation\u0026quot;, \u0026quot;training\u0026quot;)) # Save the training data tibble_train_loop \u0026lt;- tsibble_se_loop %\u0026gt;% filter(type == \u0026quot;training\u0026quot;) # Save the validation data tibble_val_loop \u0026lt;- tsibble_se_loop %\u0026gt;% filter(type == \u0026quot;validation\u0026quot;) fit_arimax \u0026lt;- tibble_train_loop %\u0026gt;% model(ARIMA(retail ~ hits_nar_lag + hits_beh_lag + pdq(1, 1, 0))) fc_arimax \u0026lt;- fit_arimax %\u0026gt;% forecast(new_data = tibble_val_loop) fc_arimax \u0026lt;- as_tibble(fc_arimax) %\u0026gt;% select(index, .mean) direct_pred \u0026lt;- rbind(direct_pred, fc_arimax) } direct_pred \u0026lt;- as_tsibble(direct_pred, index = index) arimax_direct_plot \u0026lt;- tsibble_se %\u0026gt;% mutate(color = if_else(type == \u0026quot;training\u0026quot;, \u0026quot;#7e828c\u0026quot;, \u0026quot;#7e828c\u0026quot;)) %\u0026gt;% ggplot(aes(x = index, y = retail)) + geom_line() + geom_point(aes(x = index, y = .mean), color = \u0026quot;#aa332c\u0026quot;, fill = \u0026quot;#aa332c\u0026quot;, size = 2, alpha = .8, data = direct_pred) + autolayer(direct_pred, alpha = 0.8, color = \u0026quot;#aa332c\u0026quot;) + labs( title = \u0026quot;ARIMAX model\u0026quot;, subtitle = \u0026quot;with 1-step-ahead direct forecast\u0026quot;) + scale_color_identity() + theme( axis.title.x = element_blank() ) grid.arrange(tslm_plot, arimax_plot, arimax_direct_plot, nrow = 3)  \nConclusion The direct 1-step-ahead ARIMAX forecast does a little better than both the TSLM and the ARIMAX recursive forecast at self-correcting for the last drop off in movement. But still, it essentially fails to predict that last drop 1 week ahead. Leaving that aside, the level of predictive power in the model is surprising considering its simplicity. What I take away from this experiment is that with a bit of fine-tuning and perhaps added complexity it is possible to predict a leading economic indicator with high-frequency narrative data.\nThe fact that the virus search variable did better with 1 lag as predicted while the train ticket search variable did worse is interesting. It might indicate that people don\u0026rsquo;t plan ahead when traveling by train or that train travel has an added element of spontaneity in times of high uncertainty when there is already a pent up demand for travel.\nFor future experiments it would be interesting to explore a machine learning technique with a larger and more varied narrative data set. The statistical rigor offered by conventional techniques are not as relevant in a forecasting model as they are when exploring a casual relationship.\nReferences Andersson, Michael K. and Reijer, Ard H.J. (2015), “Nowcasting”, Sveriges Riksbank Economic Review, 2015:1, Sveriges Riksbank, pp. 75-89.\nShiller, J.R. (2017) Narrative Economics. NBER Working Paper, No. 23075.\n","date":"2021-01-31T00:00:00Z","image":"https://dfornis.github.io/dfornis/p/nowcasting-a-leading-economic-indicator-in-times-of-uncertainty-with-r/nicolas-perondi--Ho_obgLFs4-unsplash_hudba9150e16cdf60946dabab36cfea944_1220069_120x120_fill_q75_box_smart1.jpg","permalink":"https://dfornis.github.io/dfornis/p/nowcasting-a-leading-economic-indicator-in-times-of-uncertainty-with-r/","title":"Nowcasting a leading economic indicator in times of uncertainty - with R"}]