<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>David Fornborg</title>
        <link>https://dfornis.github.io/dfornis/</link>
        <description>Recent content on David Fornborg</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en-us</language>
        <lastBuildDate>Sun, 31 Jan 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://dfornis.github.io/dfornis/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>Nowcasting a leading economic indicator in times of uncertainty - with R</title>
        <link>https://dfornis.github.io/dfornis/p/nowcasting-a-leading-economic-indicator-in-times-of-uncertainty-with-r/</link>
        <pubDate>Sun, 31 Jan 2021 00:00:00 +0000</pubDate>
        
        <guid>https://dfornis.github.io/dfornis/p/nowcasting-a-leading-economic-indicator-in-times-of-uncertainty-with-r/</guid>
        <description>&lt;img src="https://dfornis.github.io/dfornis/p/nowcasting-a-leading-economic-indicator-in-times-of-uncertainty-with-r/nicolas-perondi--Ho_obgLFs4-unsplash.jpg" alt="Featured image of post Nowcasting a leading economic indicator in times of uncertainty - with R" /&gt;&lt;hr&gt;
&lt;p&gt;Part of the difficulty lies in economic indicators being downstream from the development of the pandemic. Higher infection rates leads to lower mobility which leads to lower economic activity. Macroeconomic indicators are traditionally collected with a large lag. This limits their utility in times of high uncertainty. In a pandemic for example, infection rates may accelerate non-linearly (as seen in SIR-models) and are likely to react to variables such as temperature and degree of immunity, many of which remain unknown at the beginning of a pandemic. Nowcasting has been suggested by the Swedish Riksbank (Andersson, Reijer 2015) among others as a tool to make predictions with higher-frequency data. Andersson and Reijer use monthly data from surveys, financial markets and more in their nowcasting models to predict Swedish GDP. In this experiment I turned to Google Trends search data to predict movement patterns 1-week-ahead. This time horizon has proven to be relevant in the fast changing landscape that a pandemic presents.&lt;/p&gt;
&lt;p&gt;In practical terms, what would the utility be of predicting changes in movement patterns? A sharp drop in movement in public spaces can be categorized as a black swan event for affected parties, whether they are retail stores, public transport companies or government agencies. Predicted movement patterns can also be used as a leading economic indicator.&lt;/p&gt;
&lt;h2 id=&#34;theory&#34;&gt;Theory&lt;/h2&gt;
&lt;p&gt;The underlying theory has been advocated for as Narrative Economics by Robert Shiller (2019). But it has featured as a theme in many works without being mentioned by name. Its origins can be traced to the 1930&amp;rsquo;s when Keynes coined the phrase animal spirits to capture a characteristic of human behavior beyond what was imagined in the classical models of economics.&lt;/p&gt;
&lt;p&gt;The assumption is that economic outcomes, to some extent, are a function of the stories and ideas people tell themselves and others. When these stories reach a wide and receptive audience they turn economic behavior into heard behavior. If the narratives that occupy conversations and the minds of people can be measured, then they can theoretically be used to predict behavior.&lt;/p&gt;
&lt;h2 id=&#34;data&#34;&gt;Data&lt;/h2&gt;
&lt;p&gt;To capture the narrative component I used an R library called &lt;code&gt;gtrendsR&lt;/code&gt; which runs the API call to Google Trends so you don&amp;rsquo;t have to cURL it manually. The data is slightly unreliablein the sense that Google provides the amount of hits as an index which is calculated in an unknown black box of magic. The index does however  seem  to measure change in search trends over a shorter time horizon reasonably well.&lt;/p&gt;
&lt;p&gt;The query used in Google Trends was &lt;code&gt;covid&lt;/code&gt; and &lt;code&gt;virus&lt;/code&gt;. As the interest in Covid-19 rises, people are expected to go online to search for information about the virus or the situation which registers in the index. This variable is countercyclical and should be negatively correlated with movement patterns.&lt;/p&gt;
&lt;p&gt;A different and procyclical variable was used as well. For this variable my query was &lt;code&gt;sn채llt책get&lt;/code&gt; and &lt;code&gt;sj&lt;/code&gt; which are the main operators of long distance trains in Sweden. The assumption here is that people on average go online and search for train tickets 1 week ahead of departure. This variable should be positively correlated with movement patterns.&lt;/p&gt;
&lt;p&gt;For data on movement patterns I used Google Mobility Report. It was launched in the infancy of the Covid-19 pandemic to track changes in movement patterns. It calculates changes from the same days baseline categorized by country, sub region and type of location/activity (retail and recreation, parks, homes etc).&lt;/p&gt;
&lt;h2 id=&#34;model&#34;&gt;Model&lt;/h2&gt;
&lt;p&gt;One of the problems with applying a simple linear regression model is that time series data are likely to be autocorrelated which will express itself as covariance between residuals. One way of resolving this is to model the residuals as an ARIMA-process. I ended up with a (1,1,0) process here. So the model used will be a linear regression with ARIMA errors. Sometimes referred to as ARIMAX, where the X denotes an external regressor.&lt;/p&gt;
&lt;p&gt;The equation:&lt;br&gt;
$Y_t = B_1X_{1t} + B_2X_{2t} + n_t$ where $n_t = \phi n_{t-1} + \epsilon _t$ is the ARIMA error term. Notations for differencing are missing.&lt;/p&gt;
&lt;p&gt;In the model, narratives are spread at time t and have an effect on economic behavior at time t+1. Having input variables lagged at t+1 allows the use of an external regressor as fresh input for 1-step-ahead predictions in an ARIMAX model.&lt;/p&gt;
&lt;h2 id=&#34;r-code&#34;&gt;R code&lt;/h2&gt;
&lt;p&gt;Libraries:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;library(tidyverse)
library(gtrendsR) # for Google Trends API calls.
library(fable) # tidyverse compatible replacement of the forecast package.
library(feasts)
library(tsibble)
library(lubridate) # to help with some weekly time series strangeness.
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;These were the inputs in the Google Trends API call.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;query &amp;lt;- c(&amp;quot;covid&amp;quot;, &amp;quot;virus&amp;quot;)
query2 &amp;lt;- c(&amp;quot;sn채llt책get&amp;quot;, &amp;quot;sj&amp;quot;)
date &amp;lt;- c(&amp;quot;2020-03-01 2021-01-15&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;I wrote a function which loops along the query vectors and outputs the mean of hits (index of times searched) in a data frame. This allows for easy experimentation with different search queries and explorative data analysis.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;search_se &amp;lt;- data.frame()

search_se_mean &amp;lt;- function(query) {
  for(i in seq_along(search)) {
    print(search[i])
    search_se &amp;lt;- rbind(covid_se,
                      gtrends(keyword = search[i],
                              geo = &amp;quot;SE&amp;quot;,
                              time = date)[[1]])
  }

search_se_mean &amp;lt;- search_se %&amp;gt;%
  mutate(week = yearweek(date, week_start = 1)) %&amp;gt;%
  group_by(week) %&amp;gt;%
  summarise(hits = mean(hits))
}

gtrends_nar &amp;lt;- search_se_mean(query)
gtrends_beh &amp;lt;- search_se_mean(query2)

gtrends_se &amp;lt;- gtrends_nar %&amp;gt;%
  full_join(gtrends_beh, by = &amp;quot;week&amp;quot;, suffix = c(&amp;quot;_nar&amp;quot;, &amp;quot;_beh&amp;quot;))
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Plotted together:&lt;/p&gt;
&lt;p&gt;&lt;figure style=&#34;flex-grow: 200; flex-basis: 480px&#34;&gt;
		&lt;a href=&#34;https://dfornis.github.io/dfornis/dfornis/p/nowcasting-a-leading-economic-indicator-in-times-of-uncertainty-with-r/hits_plot.png&#34; data-size=&#34;1800x900&#34;&gt;&lt;img src=&#34;https://dfornis.github.io/dfornis/dfornis/p/nowcasting-a-leading-economic-indicator-in-times-of-uncertainty-with-r/hits_plot.png&#34;
				srcset=&#34;https://dfornis.github.io/dfornis/dfornis/p/nowcasting-a-leading-economic-indicator-in-times-of-uncertainty-with-r/hits_plot_hu5a943b98a0f0edf4753164ba2038e85d_150578_480x0_resize_box_2.png 480w, https://dfornis.github.io/dfornis/dfornis/p/nowcasting-a-leading-economic-indicator-in-times-of-uncertainty-with-r/hits_plot_hu5a943b98a0f0edf4753164ba2038e85d_150578_1024x0_resize_box_2.png 1024w&#34;
				width=&#34;1800&#34;
				height=&#34;900&#34;
				loading=&#34;lazy&#34;
				&gt;
		&lt;/a&gt;
		
	&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;Hits for train travel drops sharply, as one would expect, and then rebounds over the summer. Hits for the virus jumps up but starts dropping surprisingly fast. Lower levels over the summer is in line with lower spread. The index jumps up again in the autumn of 2020. This inverse relationship between narrative and behavioral predictors made intuitive sense and looked promising.&lt;/p&gt;
&lt;p&gt;The next step was to find out if the predictors had any explanatory power on the leading indicator: movement patterns.&lt;/p&gt;
&lt;p&gt;The movement data is available at &lt;a href=&#34;https://www.google.com/covid19/mobility/&#34;&gt;https://www.google.com/covid19/mobility/&lt;/a&gt; I used  the .csv-file for global data and did the filtering for my region of interest in R.
Once it&amp;rsquo;s loaded, the following code will filter for the target country with &lt;code&gt;country_region_code&lt;/code&gt;. I filtered for &lt;code&gt;sub_region_1 = &amp;quot;&amp;quot; &lt;/code&gt; in order to capture data for all of Sweden. The data is then transformed into weeks. Note that  data for &lt;code&gt;retail_and_recreation_percent_change_from_baseline&lt;/code&gt; was used. The movement patterns being predicted are in retail and recreation areas.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;gmr_se &amp;lt;- gmr %&amp;gt;%
  mutate(date = as_date(date)) %&amp;gt;%
  filter(country_region_code == &amp;quot;SE&amp;quot;,
         sub_region_1 == &amp;quot;&amp;quot;,
         date &amp;gt;= &amp;quot;2020-03-01&amp;quot; &amp;amp; date &amp;lt;= &amp;quot;2021-01-17&amp;quot;) %&amp;gt;%
  select(date, retail_and_recreation_percent_change_from_baseline) %&amp;gt;%
  mutate(week = yearweek(date, week_start = 1)) %&amp;gt;%
  group_by(week) %&amp;gt;%
  summarise(across(everything(), list(mean))) %&amp;gt;%
  rename(
    &amp;quot;retail&amp;quot; = retail_and_recreation_percent_change_from_baseline_1) %&amp;gt;%
  select(week, retail)

df_se &amp;lt;- gtrends_se %&amp;gt;% # join data sets together
  left_join(gmr_se)

df_se$retail &amp;lt;- df_se$retail + 100 # for potential differencing and log transformations
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Regressions and scatter plots:
&lt;figure style=&#34;flex-grow: 155; flex-basis: 373px&#34;&gt;
		&lt;a href=&#34;https://dfornis.github.io/dfornis/dfornis/p/nowcasting-a-leading-economic-indicator-in-times-of-uncertainty-with-r/hits_regressions_plot2.png&#34; data-size=&#34;2100x1350&#34;&gt;&lt;img src=&#34;https://dfornis.github.io/dfornis/dfornis/p/nowcasting-a-leading-economic-indicator-in-times-of-uncertainty-with-r/hits_regressions_plot2.png&#34;
				srcset=&#34;https://dfornis.github.io/dfornis/dfornis/p/nowcasting-a-leading-economic-indicator-in-times-of-uncertainty-with-r/hits_regressions_plot2_hua328f663b5bd7ed38e00c602276479d8_332050_480x0_resize_box_2.png 480w, https://dfornis.github.io/dfornis/dfornis/p/nowcasting-a-leading-economic-indicator-in-times-of-uncertainty-with-r/hits_regressions_plot2_hua328f663b5bd7ed38e00c602276479d8_332050_1024x0_resize_box_2.png 1024w&#34;
				width=&#34;2100&#34;
				height=&#34;1350&#34;
				loading=&#34;lazy&#34;
				&gt;
		&lt;/a&gt;
		
	&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;Inspecting the plots reveals that there is a linear relationship between the variables. The virus search variable does well with 1 lag, while the train ticket search does better without a lag. This will likely depend a lot on the search queries used and on the reliability of Google&amp;rsquo;s black box data. For the purpose of this experiment I stuck with the theory in order to be able to predict 1-step-ahead and continued with lagged variables.&lt;/p&gt;
&lt;p&gt;Next, preparing the data for model fitting.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;val_weeks &amp;lt;- 15 #15 weeks for validating the models

df_se_index &amp;lt;- df_se %&amp;gt;%
  mutate(index = seq_along(1:nrow(.)),
    type = if_else(index &amp;gt; max(index) - val_weeks,
    &amp;quot;validation&amp;quot;, &amp;quot;training&amp;quot;),
    hits_nar_lag = lag(hits_nar),
    hits_beh_lag = lag(hits_beh))

tsibble_se &amp;lt;- as_tsibble(df_se_index, index = index) # as time series tibble

tsibble_se_train &amp;lt;- tsibble_se %&amp;gt;%
  filter(type == &amp;quot;training&amp;quot;)

tsibble_se_val &amp;lt;- tsibble_se %&amp;gt;%
  filter(type == &amp;quot;validation&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Computing both the TSLM and the ARIMAX (1,1,0) model to see if it makes sense to model the residuals as an ARIMA-process.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;fit_tslm &amp;lt;- tsibble_se_train %&amp;gt;% # fit the model on the training data
  model(TSLM(retail ~ hits_nar_lag + hits_beh_lag))

fc_tslm &amp;lt;- fit_tslm %&amp;gt;% # forecast with the validation data
  forecast(new_data = tsibble_se_val)

fit_arimax &amp;lt;- tsibble_se_train %&amp;gt;%
  model(ARIMA(retail ~ hits_nar_lag + hits_beh_lag + pdq(1, 1, 0)))

fc_arimax &amp;lt;- fit_arimax %&amp;gt;%
  forecast(new_data = tsibble_se_val)

rmse_tslm &amp;lt;- round(accuracy(fit_tslm)[, 4], digits = 2) # extract RMSE

rmse_arimax &amp;lt;- round(accuracy(fit_arimax)[, 4], digits = 2) # extract RMSE

fit_tslm %&amp;gt;% gg_tsresiduals() 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The patterns at index &amp;gt; 18 or so didn&amp;rsquo;t look like a white noise-process. This shows up in the ACF plot as well, even though the spikes aren&amp;rsquo;t significant. The takeaway is that modeling the residuals as an ARIMA-process might prove useful.
&lt;figure style=&#34;flex-grow: 107; flex-basis: 256px&#34;&gt;
		&lt;a href=&#34;https://dfornis.github.io/dfornis/dfornis/p/nowcasting-a-leading-economic-indicator-in-times-of-uncertainty-with-r/tslm_residuals_plot.png&#34; data-size=&#34;1916x1790&#34;&gt;&lt;img src=&#34;https://dfornis.github.io/dfornis/dfornis/p/nowcasting-a-leading-economic-indicator-in-times-of-uncertainty-with-r/tslm_residuals_plot.png&#34;
				srcset=&#34;https://dfornis.github.io/dfornis/dfornis/p/nowcasting-a-leading-economic-indicator-in-times-of-uncertainty-with-r/tslm_residuals_plot_hu655848a1b355c501c0d34ca27ceea49f_384107_480x0_resize_box_2.png 480w, https://dfornis.github.io/dfornis/dfornis/p/nowcasting-a-leading-economic-indicator-in-times-of-uncertainty-with-r/tslm_residuals_plot_hu655848a1b355c501c0d34ca27ceea49f_384107_1024x0_resize_box_2.png 1024w&#34;
				width=&#34;1916&#34;
				height=&#34;1790&#34;
				loading=&#34;lazy&#34;
				alt=&#34;TSLM residuals&#34;&gt;
		&lt;/a&gt;
		
		&lt;figcaption&gt;TSLM residuals&lt;/figcaption&gt;
		
	&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;Fitting the ARIMAX-model:&lt;/p&gt;
&lt;p&gt;&lt;figure style=&#34;flex-grow: 123; flex-basis: 295px&#34;&gt;
		&lt;a href=&#34;https://dfornis.github.io/dfornis/dfornis/p/nowcasting-a-leading-economic-indicator-in-times-of-uncertainty-with-r/arimax_residuals_plot.png&#34; data-size=&#34;904x733&#34;&gt;&lt;img src=&#34;https://dfornis.github.io/dfornis/dfornis/p/nowcasting-a-leading-economic-indicator-in-times-of-uncertainty-with-r/arimax_residuals_plot.png&#34;
				srcset=&#34;https://dfornis.github.io/dfornis/dfornis/p/nowcasting-a-leading-economic-indicator-in-times-of-uncertainty-with-r/arimax_residuals_plot_hu4f5034fb73b254b14675345864cce34e_62048_480x0_resize_box_2.png 480w, https://dfornis.github.io/dfornis/dfornis/p/nowcasting-a-leading-economic-indicator-in-times-of-uncertainty-with-r/arimax_residuals_plot_hu4f5034fb73b254b14675345864cce34e_62048_1024x0_resize_box_2.png 1024w&#34;
				width=&#34;904&#34;
				height=&#34;733&#34;
				loading=&#34;lazy&#34;
				alt=&#34;ARIMAX residuals&#34;&gt;
		&lt;/a&gt;
		
		&lt;figcaption&gt;ARIMAX residuals&lt;/figcaption&gt;
		
	&lt;/figure&gt;
Evaluating the ARIMAX-residuals, they looked more like a stationary white noise process. No significant spikes.&lt;/p&gt;
&lt;p&gt;Plotting the models and forecasts produced with Fable:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;tslm_plot &amp;lt;- 
  tsibble_se %&amp;gt;%
  mutate(color = if_else(type == &amp;quot;training&amp;quot;, &amp;quot;#7e828c&amp;quot;, &amp;quot;#7e828c&amp;quot;)) %&amp;gt;%
  ggplot(aes(x = index, y = retail)) +
  geom_line() +
  autolayer(fc_tslm, alpha = 0.5, color = &amp;quot;#aa332c&amp;quot;) +
  geom_line(aes(color = color), alpha = 0.8) +
  geom_line(aes(y = .fitted, color = &amp;quot;#aa332c&amp;quot;), data = augment(fit_tslm)) +
  labs(
    title = &amp;quot;TSLM model&amp;quot;,
    subtitle = paste0(&amp;quot;RMSE = &amp;quot;, rmse_tslm)) +
  scale_color_identity() 
  
arimax_plot &amp;lt;- 
  tsibble_se %&amp;gt;%
  mutate(color = if_else(type == &amp;quot;training&amp;quot;, &amp;quot;#7e828c&amp;quot;, &amp;quot;#7e828c&amp;quot;)) %&amp;gt;%
  ggplot(aes(x = index, y = retail)) +
  geom_line() +
  autolayer(fc_arimax, alpha = 0.5, color = &amp;quot;#aa332c&amp;quot;) +
  geom_line(aes(color = color), alpha = 0.8) +
  geom_line(aes(y = .fitted, color = &amp;quot;#aa332c&amp;quot;), data = augment(fit_arimax)) +
  labs(
    title = &amp;quot;ARIMAX model&amp;quot;,
    subtitle = paste0(&amp;quot;RMSE = &amp;quot;, rmse_arimax)) +
  scale_color_identity() 
  
grid.arrange(tslm_plot, arimax_plot, nrow = 2)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;figure style=&#34;flex-grow: 100; flex-basis: 240px&#34;&gt;
		&lt;a href=&#34;https://dfornis.github.io/dfornis/dfornis/p/nowcasting-a-leading-economic-indicator-in-times-of-uncertainty-with-r/tslm_arimax_forecasts.png&#34; data-size=&#34;2100x2100&#34;&gt;&lt;img src=&#34;https://dfornis.github.io/dfornis/dfornis/p/nowcasting-a-leading-economic-indicator-in-times-of-uncertainty-with-r/tslm_arimax_forecasts.png&#34;
				srcset=&#34;https://dfornis.github.io/dfornis/dfornis/p/nowcasting-a-leading-economic-indicator-in-times-of-uncertainty-with-r/tslm_arimax_forecasts_hu4346fcd9ca4674303bb43313d3e76666_400552_480x0_resize_box_2.png 480w, https://dfornis.github.io/dfornis/dfornis/p/nowcasting-a-leading-economic-indicator-in-times-of-uncertainty-with-r/tslm_arimax_forecasts_hu4346fcd9ca4674303bb43313d3e76666_400552_1024x0_resize_box_2.png 1024w&#34;
				width=&#34;2100&#34;
				height=&#34;2100&#34;
				loading=&#34;lazy&#34;
				&gt;
		&lt;/a&gt;
		
	&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;m a bit surprised that the fitted TSLM model performed in parity with the ARIMAX model. I think this might vary a lot depending on the data you end up with. Both models do a decent job on the training data. But they both do a poor job at forecasting the sharp drop in movement that occurs at the end of the time series. I should point out that the ARIMAX model is forecasting the AR(1)-process recursively here. Consequently, there is a mean reversion and it looses its effect over time.&lt;/p&gt;
&lt;p&gt;Since I&amp;rsquo;m interested in the 1-step-ahead forecast, I wrote the loop below to capture what that looks like on the validation data. The point here is to capture the direct 1-step-ahead forecast instead of a recursive forecast, and thereby utilize the full potential of the ARIMAX-model.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;tsibble_se_loop &amp;lt;- data.frame()
direct_pred &amp;lt;- data.frame()
index &amp;lt;- 15:nrow(tsibble_se)
val_weeks = 1

for(i in index) {
  tsibble_se_loop &amp;lt;- df_se %&amp;gt;%
    mutate(index = seq_along(1:nrow(.)),
           hits_nar_lag = lag(hits_nar),
           hits_beh_lag = lag(hits_beh)) %&amp;gt;%
    as_tsibble(., index = index) %&amp;gt;%
    filter(index &amp;lt; index[i]) %&amp;gt;%
    mutate(type = if_else(index &amp;gt; max(index) - val_weeks,
                          &amp;quot;validation&amp;quot;, &amp;quot;training&amp;quot;))
  
  # Save the training data
  tibble_train_loop &amp;lt;- tsibble_se_loop %&amp;gt;%
    filter(type == &amp;quot;training&amp;quot;)
  
  # Save the validation data
  tibble_val_loop &amp;lt;- tsibble_se_loop %&amp;gt;%
    filter(type == &amp;quot;validation&amp;quot;)
  
  fit_arimax &amp;lt;- tibble_train_loop %&amp;gt;%
    model(ARIMA(retail ~ hits_nar_lag + hits_beh_lag + pdq(1, 1, 0)))
  fc_arimax &amp;lt;- fit_arimax %&amp;gt;%
    forecast(new_data = tibble_val_loop)
  
  fc_arimax &amp;lt;- as_tibble(fc_arimax) %&amp;gt;%
    select(index, .mean)
  
  direct_pred &amp;lt;- rbind(direct_pred, fc_arimax)
}

direct_pred &amp;lt;- as_tsibble(direct_pred, index = index)

arimax_direct_plot &amp;lt;- 
  tsibble_se %&amp;gt;%
  mutate(color = if_else(type == &amp;quot;training&amp;quot;, &amp;quot;#7e828c&amp;quot;, &amp;quot;#7e828c&amp;quot;)) %&amp;gt;%
  ggplot(aes(x = index, y = retail)) +
  geom_line() +
  geom_point(aes(x = index, y = .mean), color = &amp;quot;#aa332c&amp;quot;, fill = &amp;quot;#aa332c&amp;quot;, size = 2, alpha = .8, data = direct_pred) +
  autolayer(direct_pred, alpha = 0.8, color = &amp;quot;#aa332c&amp;quot;)  +
  labs(
    title = &amp;quot;ARIMAX model&amp;quot;,
    subtitle = &amp;quot;with 1-step-ahead direct forecast&amp;quot;) +
  scale_color_identity() +
  theme(
    axis.title.x = element_blank()
  )

grid.arrange(tslm_plot, arimax_plot, arimax_direct_plot,  nrow = 3)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;figure style=&#34;flex-grow: 100; flex-basis: 240px&#34;&gt;
		&lt;a href=&#34;https://dfornis.github.io/dfornis/dfornis/p/nowcasting-a-leading-economic-indicator-in-times-of-uncertainty-with-r/tslm_arimax_direct_forecasts.png&#34; data-size=&#34;2100x2100&#34;&gt;&lt;img src=&#34;https://dfornis.github.io/dfornis/dfornis/p/nowcasting-a-leading-economic-indicator-in-times-of-uncertainty-with-r/tslm_arimax_direct_forecasts.png&#34;
				srcset=&#34;https://dfornis.github.io/dfornis/dfornis/p/nowcasting-a-leading-economic-indicator-in-times-of-uncertainty-with-r/tslm_arimax_direct_forecasts_hu4346fcd9ca4674303bb43313d3e76666_449833_480x0_resize_box_2.png 480w, https://dfornis.github.io/dfornis/dfornis/p/nowcasting-a-leading-economic-indicator-in-times-of-uncertainty-with-r/tslm_arimax_direct_forecasts_hu4346fcd9ca4674303bb43313d3e76666_449833_1024x0_resize_box_2.png 1024w&#34;
				width=&#34;2100&#34;
				height=&#34;2100&#34;
				loading=&#34;lazy&#34;
				&gt;
		&lt;/a&gt;
		
	&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;The direct 1-step-ahead ARIMAX forecast does a little better than both the TSLM and the ARIMAX recursive forecast at self-correcting for the last drop off in movement. But still, it essentially fails to predict that last drop 1 week ahead. Leaving that aside, the level of predictive power in the model is surprising considering its simplicity. What I take away from this experiment is that with a bit of fine-tuning and perhaps added complexity it is possible to predict a leading economic indicator with high-frequency narrative data gathered  Google Trends.&lt;/p&gt;
&lt;p&gt;Since it&amp;rsquo;s a forecasting model, the highest requirements for statistical rigor does not necessarily apply. Given that, it would be interesting to apply a machine-learning technique for nowcasting with a larger and more varied narrative data input.&lt;/p&gt;
</description>
        </item>
        
    </channel>
</rss>
